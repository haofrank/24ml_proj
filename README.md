# Multimodal LLMs for Annotating Complex Cultural Memes in Movie Dialogues
## - NYU 24 Spring Machine Learning Group Project

Contributors:
Yihan Li (@Litou-lyh), Hao Li (@haofrank), Jiayu Gu (@), Guanshi Wang (@oyster14)
{yl10798, hl5262, jg7956, gw2310}@nyu.edu

## Tentative plan
- Week 0401
  - [X] Built conda env image on Greene. By: yihan
  - [ ] Run vllm or any LLM to get reasonable output (on greene). Assign: Hao
  - [ ] Find movie dialogue (script) dataset. Assign:
  - [ ] Design prompts (append to dialogues). Can test using GPT4 / Claude 3 first. Assign:
  - [ ] Survey on serving techs (e.g. quantization). Assign:

- Week 0408
  - [ ] Write streaming input scripts. Assign:
  - [ ] Benchmark mean response time with streaming input. (may also include memory usage). Assign:
  - [ ] Try current serving techs. Assign:
  - [ ] Try distributed inference. Assign:
- Week 0415
- Week 0422
- Week 0429
- 
